# nnUNet baseline algorithm for autoPETIII challenge

Source code for the nnUNet baseline algorithm container for autoPETIII challenge. Information about the 
submission can be found [here](https://autopet-iii.grand-challenge.org/submission/) and in the [grand challenge 
documentation](https://grand-challenge.org/documentation/).

## Task
Best ranked model wins! The rules are simple: Train a model which generalizes well on FDG and PSMA data. Or train two 
models and combine them? You are free to choose. You can use additional data which is publicly available. This 
baseline model is out of competition!

## Usage 

In order to use the baseline you first need to download the baseline weights via `bash download_model_weights.sh`. 
After that you can build the container by running `bash build.sh`. In order to upload the container, you will need to
save the image via `bash export.sh`.

## Testing

Use a python 3.10 based environment and install the requirements.txt file via `pip install -r requirements.txt`. 
Make sure model weights exist in `/nnUNet_results`. Download the baseline weights by running `bash download_model_weights.sh`. 
Then run `bash create_expected_output.sh` to create an expected_output mask. After that you can run `bash test.sh`.

The code provided is part of a baseline model for the AutoPET III challenge, utilizing an ensemble of three different 3D segmentation models: UNet3D, ResUNet3D, and UNETR. The goal of the ensemble approach is to fuse the predictions of these models for better generalization and accuracy when segmenting medical images from FDG and PSMA PET/CT scans.

Key Components
Models and Architecture:

UNet3D: A 3D U-Net variant with a typical encoder-decoder structure for volumetric medical image segmentation.
ResUNet3D: A U-Net variant that incorporates residual connections to improve gradient flow and model accuracy.
UNETR: A transformer-based architecture for volumetric medical image segmentation, leveraging self-attention mechanisms for improved long-range dependencies.
Ensemble Method:

The code loads pretrained weights for all three models and then averages their predictions through an ensemble strategy.
Each model is fed the input image, and their respective outputs (segmentation maps) are combined using element-wise averaging to form a final prediction.
Dataset:

The MedicalDataset class (imported from the dataset module) loads the training images and labels from the specified directories.
The DataLoader iterates over the dataset to process each input batch and generate predictions.
Prediction and Thresholding:

The ensemble prediction is generated by averaging the predictions from the three models.
A threshold (default 0.5) is applied to the ensemble output to create a binary mask for tumor segmentation.
Evaluation and Processing:

After generating the ensembled binary mask, the code can be extended to save or evaluate these masks against ground truth labels.

nnUNet Baseline Algorithm for AutoPET III Challenge
This repository contains the source code for the nnUNet-based baseline algorithm for the AutoPET III challenge. The algorithm combines multiple models to provide robust segmentation of PET/CT images for tumor detection.

Models
This baseline model implements three distinct 3D segmentation architectures:

UNet3D: A 3D version of the U-Net architecture tailored for volumetric segmentation.
ResUNet3D: A residual U-Net variant that incorporates skip connections to improve learning efficiency and accuracy.
UNETR: A transformer-based model that utilizes self-attention to capture global contextual information in volumetric data.
These models are ensembled to generate a robust final segmentation.

Ensemble Strategy
The model predictions are combined using an ensemble method where the predictions from UNet3D, ResUNet3D, and UNETR are averaged to provide the final segmentation output. This improves generalization across different types of input data (FDG and PSMA).

Usage
Download Model Weights: To use the pretrained models, download the model weights:

bash
Copy code
bash download_model_weights.sh
Build the Docker Container: After downloading the model weights, build the Docker container:

bash
Copy code
bash build.sh
Export the Docker Image: Once the container is built, you can export it for submission:

bash
Copy code
bash export.sh
Test Locally: To test the baseline model locally:

Create an environment with Python 3.10.
Install the necessary dependencies:
bash
Copy code
pip install -r requirements.txt
Make sure the model weights exist in the /nnUNet_results folder.
Generate an expected output for a test image by running:

bash create_expected_output.sh

Run the tests:

bash test.sh
Ensemble Model Inference
The ensemble process involves loading the models, making predictions for each input image, and combining these predictions using the following logic:

def ensemble_predictions(models, image):
    predictions = [torch.sigmoid(model(image)).detach() for model in models]
    ensemble_prediction = torch.mean(torch.stack(predictions), dim=0)
    return ensemble_prediction

Dataset
The dataset is expected to be structured as follows:

PET and CT images are stored in the /imagesTr directory.
Ground truth labels for segmentation are stored in the /labelsTr directory.
These directories are configured within the MedicalDataset class.


